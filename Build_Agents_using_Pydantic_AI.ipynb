{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic-ai\r\n",
      "  Downloading pydantic_ai-0.2.14-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting pydantic-ai-slim==0.2.14 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pydantic_ai_slim-0.2.14-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting eval-type-backport>=0.2.0 (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\r\n",
      "Collecting griffe>=1.3.2 (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\r\n",
      "Requirement already satisfied: httpx>=0.27 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (0.28.1)\r\n",
      "Collecting opentelemetry-api>=1.28.0 (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading opentelemetry_api-1.34.0-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Collecting pydantic-graph==0.2.14 (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pydantic_graph-0.2.14-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting pydantic>=2.10 (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\r\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Collecting fasta2a==0.2.14 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading fasta2a-0.2.14-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting anthropic>=0.52.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached anthropic-0.52.2-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting boto3>=1.35.74 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached boto3-1.38.29-py3-none-any.whl.metadata (6.6 kB)\r\n",
      "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: prompt-toolkit>=3 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (3.0.51)\r\n",
      "Collecting rich>=13 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\r\n",
      "Collecting cohere>=5.13.11 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting pydantic-evals==0.2.14 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pydantic_evals-0.2.14-py3-none-any.whl.metadata (7.8 kB)\r\n",
      "Collecting google-genai>=1.15.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading google_genai-1.18.0-py3-none-any.whl.metadata (35 kB)\r\n",
      "Collecting groq>=0.15.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached groq-0.26.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting mcp>=1.9.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached mcp-1.9.2-py3-none-any.whl.metadata (28 kB)\r\n",
      "Collecting mistralai>=1.2.5 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached mistralai-1.8.1-py3-none-any.whl.metadata (33 kB)\r\n",
      "Collecting openai>=1.75.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached openai-1.84.0-py3-none-any.whl.metadata (25 kB)\r\n",
      "Collecting google-auth>=2.36.0 (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (2.32.3)\r\n",
      "Collecting starlette>0.29.0 (from fasta2a==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: anyio>=0 in ./.venv/lib/python3.13/site-packages (from pydantic-evals==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (4.9.0)\r\n",
      "Collecting logfire-api>=1.2.0 (from pydantic-evals==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached logfire_api-3.17.0-py3-none-any.whl.metadata (972 bytes)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.2 in ./.venv/lib/python3.13/site-packages (from pydantic-evals==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (6.0.2)\r\n",
      "Collecting distro<2,>=1.7.0 (from anthropic>=0.52.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic>=0.52.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading jiter-0.10.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\r\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.13/site-packages (from anthropic>=0.52.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (1.3.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in ./.venv/lib/python3.13/site-packages (from anthropic>=0.52.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (4.14.0)\r\n",
      "Collecting botocore<1.39.0,>=1.38.29 (from boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached botocore-1.38.29-py3-none-any.whl.metadata (5.7 kB)\r\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3>=1.35.74->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading fastavro-1.11.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (5.7 kB)\r\n",
      "Collecting httpx-sse==0.4.0 (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pydantic_core-2.34.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting tokenizers<1,>=0.15 (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached types_requests-2.32.0.20250602-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\r\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai>=1.15.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting colorama>=0.4 (from griffe>=1.3.2->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (1.0.9)\r\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (3.10)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (0.16.0)\r\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp>=1.9.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\r\n",
      "Collecting python-multipart>=0.0.9 (from mcp>=1.9.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "Collecting sse-starlette>=1.6.1 (from mcp>=1.9.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached sse_starlette-2.3.6-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting uvicorn>=0.23.1 (from mcp>=1.9.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.13/site-packages (from mistralai>=1.2.5->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (2.9.0.post0)\r\n",
      "Collecting tqdm>4 (from openai>=1.75.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.28.0->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\r\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.13/site-packages (from prompt-toolkit>=3->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (0.2.13)\r\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.10->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting pydantic-core<3.0.0,>=2.18.2 (from cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests>=2.32.2->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (2.4.0)\r\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.13/site-packages (from rich>=13->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (2.19.1)\r\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==0.2.14->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading zipp-3.22.0-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5.2->mcp>=1.9.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->mistralai>=1.2.5->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (1.17.0)\r\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading huggingface_hub-0.32.4-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting click>=7.0 (from uvicorn>=0.23.1->mcp>=1.9.0->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai) (25.0)\r\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere>=5.13.11->pydantic-ai-slim[a2a,anthropic,bedrock,cli,cohere,evals,google,groq,mcp,mistral,openai,vertexai]==0.2.14->pydantic-ai)\r\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\r\n",
      "Downloading pydantic_ai-0.2.14-py3-none-any.whl (10 kB)\r\n",
      "Downloading pydantic_ai_slim-0.2.14-py3-none-any.whl (186 kB)\r\n",
      "Downloading fasta2a-0.2.14-py3-none-any.whl (15 kB)\r\n",
      "Downloading pydantic_evals-0.2.14-py3-none-any.whl (51 kB)\r\n",
      "Downloading pydantic_graph-0.2.14-py3-none-any.whl (27 kB)\r\n",
      "Using cached anthropic-0.52.2-py3-none-any.whl (286 kB)\r\n",
      "Using cached argcomplete-3.6.2-py3-none-any.whl (43 kB)\r\n",
      "Using cached boto3-1.38.29-py3-none-any.whl (139 kB)\r\n",
      "Using cached cohere-5.15.0-py3-none-any.whl (259 kB)\r\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\r\n",
      "Using cached eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\r\n",
      "Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\r\n",
      "Downloading google_genai-1.18.0-py3-none-any.whl (199 kB)\r\n",
      "Using cached griffe-1.7.3-py3-none-any.whl (129 kB)\r\n",
      "Using cached groq-0.26.0-py3-none-any.whl (129 kB)\r\n",
      "Using cached mcp-1.9.2-py3-none-any.whl (131 kB)\r\n",
      "Using cached mistralai-1.8.1-py3-none-any.whl (373 kB)\r\n",
      "Using cached openai-1.84.0-py3-none-any.whl (725 kB)\r\n",
      "Downloading opentelemetry_api-1.34.0-py3-none-any.whl (65 kB)\r\n",
      "Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)\r\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m1.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached rich-14.0.0-py3-none-any.whl (243 kB)\r\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\r\n",
      "Using cached botocore-1.38.29-py3-none-any.whl (13.6 MB)\r\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\r\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\r\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading fastavro-1.11.1-cp313-cp313-macosx_10_13_universal2.whl (931 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m931.5/931.5 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\r\n",
      "Downloading jiter-0.10.0-cp313-cp313-macosx_11_0_arm64.whl (318 kB)\r\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\n",
      "Using cached logfire_api-3.17.0-py3-none-any.whl (80 kB)\r\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\r\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\r\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\r\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\r\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\r\n",
      "Using cached s3transfer-0.13.0-py3-none-any.whl (85 kB)\r\n",
      "Using cached sse_starlette-2.3.6-py3-none-any.whl (10 kB)\r\n",
      "Using cached starlette-0.47.0-py3-none-any.whl (72 kB)\r\n",
      "Using cached tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n",
      "Using cached types_requests-2.32.0.20250602-py3-none-any.whl (20 kB)\r\n",
      "Using cached uvicorn-0.34.3-py3-none-any.whl (62 kB)\r\n",
      "Downloading websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\r\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\r\n",
      "Downloading huggingface_hub-0.32.4-py3-none-any.whl (512 kB)\r\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\r\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\r\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\r\n",
      "Downloading zipp-3.22.0-py3-none-any.whl (9.8 kB)\r\n",
      "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\r\n",
      "Downloading hf_xet-1.1.3-cp37-abi3-macosx_11_0_arm64.whl (2.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.2/2.2 MB\u001B[0m \u001B[31m529.0 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\r\n",
      "Installing collected packages: zipp, websockets, typing-inspection, types-requests, tqdm, python-multipart, python-dotenv, pydantic-core, pyasn1, mdurl, logfire-api, jmespath, jiter, httpx-sse, hf-xet, fsspec, filelock, fastavro, eval-type-backport, distro, colorama, click, cachetools, argcomplete, annotated-types, uvicorn, starlette, sse-starlette, rsa, pydantic, pyasn1-modules, markdown-it-py, importlib-metadata, huggingface-hub, griffe, botocore, tokenizers, s3transfer, rich, pydantic-settings, pydantic-graph, opentelemetry-api, openai, mistralai, groq, google-auth, anthropic, pydantic-ai-slim, mcp, google-genai, fasta2a, cohere, boto3, pydantic-evals, pydantic-ai\r\n",
      "Successfully installed annotated-types-0.7.0 anthropic-0.52.2 argcomplete-3.6.2 boto3-1.38.29 botocore-1.38.29 cachetools-5.5.2 click-8.2.1 cohere-5.15.0 colorama-0.4.6 distro-1.9.0 eval-type-backport-0.2.2 fasta2a-0.2.14 fastavro-1.11.1 filelock-3.18.0 fsspec-2025.5.1 google-auth-2.40.3 google-genai-1.18.0 griffe-1.7.3 groq-0.26.0 hf-xet-1.1.3 httpx-sse-0.4.0 huggingface-hub-0.32.4 importlib-metadata-8.7.0 jiter-0.10.0 jmespath-1.0.1 logfire-api-3.17.0 markdown-it-py-3.0.0 mcp-1.9.2 mdurl-0.1.2 mistralai-1.8.1 openai-1.84.0 opentelemetry-api-1.34.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.5 pydantic-ai-0.2.14 pydantic-ai-slim-0.2.14 pydantic-core-2.33.2 pydantic-evals-0.2.14 pydantic-graph-0.2.14 pydantic-settings-2.9.1 python-dotenv-1.1.0 python-multipart-0.0.20 rich-14.0.0 rsa-4.9.1 s3transfer-0.13.0 sse-starlette-2.3.6 starlette-0.47.0 tokenizers-0.21.1 tqdm-4.67.1 types-requests-2.32.0.20250602 typing-inspection-0.4.1 uvicorn-0.34.3 websockets-15.0.1 zipp-3.22.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 4,
   "source": "pip install pydantic-ai",
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:11.571100Z",
     "start_time": "2025-06-04T18:15:08.099426Z"
    }
   },
   "cell_type": "code",
   "source": "pip install \"pydantic-ai-slim[tavily]\"",
   "id": "e24dccbbcf261c0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic-ai-slim[tavily] in ./.venv/lib/python3.13/site-packages (0.2.14)\r\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (0.2.2)\r\n",
      "Requirement already satisfied: griffe>=1.3.2 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (1.7.3)\r\n",
      "Requirement already satisfied: httpx>=0.27 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (0.28.1)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.28.0 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (1.34.0)\r\n",
      "Requirement already satisfied: pydantic-graph==0.2.14 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (0.2.14)\r\n",
      "Requirement already satisfied: pydantic>=2.10 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (2.11.5)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.13/site-packages (from pydantic-ai-slim[tavily]) (0.4.1)\r\n",
      "Collecting tavily-python>=0.5.0 (from pydantic-ai-slim[tavily])\r\n",
      "  Downloading tavily_python-0.7.4-py3-none-any.whl.metadata (7.5 kB)\r\n",
      "Requirement already satisfied: logfire-api>=1.2.0 in ./.venv/lib/python3.13/site-packages (from pydantic-graph==0.2.14->pydantic-ai-slim[tavily]) (3.17.0)\r\n",
      "Requirement already satisfied: colorama>=0.4 in ./.venv/lib/python3.13/site-packages (from griffe>=1.3.2->pydantic-ai-slim[tavily]) (0.4.6)\r\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim[tavily]) (4.9.0)\r\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim[tavily]) (2025.4.26)\r\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim[tavily]) (1.0.9)\r\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.13/site-packages (from httpx>=0.27->pydantic-ai-slim[tavily]) (3.10)\r\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim[tavily]) (0.16.0)\r\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim[tavily]) (8.7.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.13/site-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim[tavily]) (4.14.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.10->pydantic-ai-slim[tavily]) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.13/site-packages (from pydantic>=2.10->pydantic-ai-slim[tavily]) (2.33.2)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.13/site-packages (from tavily-python>=0.5.0->pydantic-ai-slim[tavily]) (2.32.3)\r\n",
      "Collecting tiktoken>=0.5.1 (from tavily-python>=0.5.0->pydantic-ai-slim[tavily])\r\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim[tavily]) (3.22.0)\r\n",
      "Collecting regex>=2022.1.18 (from tiktoken>=0.5.1->tavily-python>=0.5.0->pydantic-ai-slim[tavily])\r\n",
      "  Using cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.13/site-packages (from requests->tavily-python>=0.5.0->pydantic-ai-slim[tavily]) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.13/site-packages (from requests->tavily-python>=0.5.0->pydantic-ai-slim[tavily]) (2.4.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.13/site-packages (from anyio->httpx>=0.27->pydantic-ai-slim[tavily]) (1.3.1)\r\n",
      "Downloading tavily_python-0.7.4-py3-none-any.whl (15 kB)\r\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m640.5 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\r\n",
      "Installing collected packages: regex, tiktoken, tavily-python\r\n",
      "Successfully installed regex-2024.11.6 tavily-python-0.7.4 tiktoken-0.9.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m25.0.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.1.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:32.043126Z",
     "start_time": "2025-06-04T18:15:32.038294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ],
   "id": "7367fa7b839a8c6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:47.214365Z",
     "start_time": "2025-06-04T18:15:46.755330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from pydantic_ai.agent import Agent\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool"
   ],
   "id": "434158e0e9298ff5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:15:57.414133Z",
     "start_time": "2025-06-04T18:15:57.410736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setup Groq API Key\n",
    "os.environ[\"GROQ_API_KEY\"] = \"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\""
   ],
   "id": "30612cae10a27c4e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:16:07.158648Z",
     "start_time": "2025-06-04T18:16:07.148933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tavily API key\n",
    "TAVILY_API_KEY = \"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\""
   ],
   "id": "d830af49d8e56a2f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:16:17.098707Z",
     "start_time": "2025-06-04T18:16:17.004158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent = Agent(\n",
    "    'groq:llama-3.1-8b-instant',\n",
    "    tools=[tavily_search_tool(TAVILY_API_KEY)],\n",
    "    system_prompt='Search Tavily for the given query and return the results.',\n",
    ")"
   ],
   "id": "e4c537eb79ffcb83",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T18:46:04.865335Z",
     "start_time": "2025-06-04T18:46:02.442626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = agent.run_sync('Tell me the top news in the GenAI world recently.')\n",
    "print(result.output)"
   ],
   "id": "fd91b10904d022e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the search results, it appears that there are several recent developments in the GenAI space. Some of the top news include:\n",
      "\n",
      "* GenAI announces delay in filing its annual financial statements and issuance of MCTO.\n",
      "* Beyond tech transformation, GenAI is a change in societal configuration: TCS UK Country Head.\n",
      "* Ant International ships Alipay+ GenAI Cockpit, an AI-as-a-Service (AIaaS) platform that empowers fintech companies and super apps to build AI-agentic and ultimately AI-native financial services.\n",
      "* AI for lawyers: Win back your time using technology.\n",
      "\n",
      "These articles suggest that GenAI is having a significant impact on various industries and societies, and is being seen as a game-changing technology.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6a28b1fd144adc0c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
